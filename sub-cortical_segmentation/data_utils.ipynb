{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "877dd2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from nibabel import load as load_nii\n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfb3adc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/mnt/F2F25460F2542ADD/MedicalAnalysis/DataSets/ISBI/train/'\n",
    "t1_name='mprage.nii'\n",
    "mask_name='mask1.nii'\n",
    "patch_size=(32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ecf404b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/microsoft/Medical_Analysis/Code/Environments/medical_pytorch_env/lib/python3.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n",
      "  \n",
      "/home/microsoft/Medical_Analysis/Code/Environments/medical_pytorch_env/lib/python3.7/site-packages/ipykernel_launcher.py:12: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# Get the names of the images and load them and normalize images\n",
    "subjects = [f for f in sorted(os.listdir(root_dir)) if os.path.isdir(os.path.join(root_dir, f))]\n",
    "subjects = subjects[:2]\n",
    "image_names = [os.path.join(root_dir, subject, t1_name) for subject in subjects]\n",
    "\n",
    "images = [fix_shape(load_nii(name).get_data()) for name in image_names]\n",
    "images_norm = [(im.astype(np.float32) - im[np.nonzero(im)].mean()) / im[np.nonzero(im)].std() for im in images]\n",
    "# images_norm = [image * (256.0 / (np.max(image) - np.min(image))) for image in images]\n",
    "\n",
    "# load labels\n",
    "label_names = [os.path.join(root_dir, subject, mask_name) for subject in subjects]\n",
    "labels = [fix_shape(load_nii(name).get_data()) for name in label_names]\n",
    "\n",
    "# positive classes (not background) classes between 1 and 14\n",
    "p_vox_coord_pos = [get_mask_voxels(np.logical_and(mask > 0, mask < 15)) for mask in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36bbc5d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "`pad_width` must be of integral type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3751/1206942059.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch_half\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mnew_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'constant'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstant_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m axial_x_pos_patches = [np.array(get_patches(image, centers, size, mode='axial')) for image, centers in\n\u001b[1;32m     24\u001b[0m                            zip(images_norm, p_vox_coord_pos)]\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpad\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/Medical_Analysis/Code/Environments/medical_pytorch_env/lib/python3.7/site-packages/numpy/lib/arraypad.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpad_width\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'i'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`pad_width` must be of integral type.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;31m# Broadcast to shape (array.ndim, 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: `pad_width` must be of integral type."
     ]
    }
   ],
   "source": [
    "image=images_norm[0]\n",
    "centers=p_vox_coord_pos[0]\n",
    "mode='axial'\n",
    "\n",
    "# By doing this we allow pooling when using encoders/unets.\n",
    "patches = []\n",
    "list_of_tuples = all([isinstance(center, tuple) for center in centers])\n",
    "#sizes_match = [len(center) == len(patch_size) for center in centers]\n",
    "\n",
    "# select between axial / coronal / saggital  patches\n",
    "if mode == 'axial':\n",
    "    patch_size = (patch_size[0], patch_size[1], 1)\n",
    "if mode == 'coronal':\n",
    "    patch_size = (patch_size[0], 1, patch_size[1])\n",
    "if mode == 'saggital':\n",
    "    patch_size = (1, patch_size[0], patch_size[1])\n",
    "    \n",
    "patch_half = tuple([idx/2 for idx in patch_size])\n",
    "new_centers = [map(add, center, patch_half) for center in centers]\n",
    "padding = tuple((idx, size-idx) for idx, size in zip(patch_half, patch_size))\n",
    "\n",
    "new_image = np.pad(image, padding, mode='constant', constant_values=0)\n",
    "axial_x_pos_patches = [np.array(get_patches(image, centers, size, mode='axial')) for image, centers in\n",
    "                           zip(images_norm, p_vox_coord_pos)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e7c6762",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "`pad_width` must be of integral type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3751/1000667820.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'constant'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstant_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpad\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/Medical_Analysis/Code/Environments/medical_pytorch_env/lib/python3.7/site-packages/numpy/lib/arraypad.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpad_width\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'i'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`pad_width` must be of integral type.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;31m# Broadcast to shape (array.ndim, 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: `pad_width` must be of integral type."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6379a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_patch_vectors(options, name, label_name, dir_name, size, random_state, balance_neg=True):\n",
    "    \"\"\"\n",
    "    Generate all patch vectors for all subjects and one sequence (name). This is done for each image view (axial, coronal and axial)\n",
    "    In subcortical brain tissue segmentation, I am extracting all positive class voxels (classes from 1 to 14) and the same number of\n",
    "    negatives (background) voxels (class 15).\n",
    "\n",
    "    Inputs:\n",
    "    - name: T1 image name\n",
    "    - label_name: label name\n",
    "    - dir_name = absolute path of the database images\n",
    "    - size: patch size [p1, p2]\n",
    "    - random_state: random seed\n",
    "\n",
    "    Outputs:\n",
    "    - x_axial: a list containing all the selected patches for all images for the axial view [image_num, num_samples, p1 , p2]\n",
    "    - y_axial: a list containing all the labels for all image patches (axial view) [image_num, num_samples, p1 , p2]\n",
    "    ...\n",
    "    - y_saggital, a list containing all the labels for all image patches (saggital view) [image_num, num_samples, p1 , p2]\n",
    "    - vox_positions: voxel coordinates for each of the patches [image_num, x, y, z]\n",
    "    - image names\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    axial_y_pos_patches = [np.array(get_patches(image, centers, size, mode='axial')) for image, centers in\n",
    "                           zip(labels, p_vox_coord_pos)]\n",
    "    cor_x_pos_patches = [np.array(get_patches(image, centers, size, mode='coronal')) for image, centers in\n",
    "                         zip(images_norm, p_vox_coord_pos)]\n",
    "    cor_y_pos_patches = [np.array(get_patches(image, centers, size, mode='coronal')) for image, centers in\n",
    "                         zip(labels, p_vox_coord_pos)]\n",
    "    sag_x_pos_patches = [np.array(get_patches(image, centers, size, mode='saggital')) for image, centers in\n",
    "                         zip(images_norm, p_vox_coord_pos)]\n",
    "    sag_y_pos_patches = [np.array(get_patches(image, centers, size, mode='saggital')) for image, centers in\n",
    "                         zip(labels, p_vox_coord_pos)]\n",
    "\n",
    "    if balance_neg:\n",
    "        n_vox_coord_pos = [get_mask_voxels(mask == 15, size=len(p)) for mask, p in zip(labels, p_vox_coord_pos)]\n",
    "    else:\n",
    "        n_vox_coord_pos = [get_mask_voxels(mask == 15) for mask, p in zip(labels, p_vox_coord_pos)]\n",
    "\n",
    "    axial_x_neg_patches = [np.array(get_patches(image, centers, size, mode='axial')) for image, centers in\n",
    "                           zip(images_norm, n_vox_coord_pos)]\n",
    "    axial_y_neg_patches = [np.array(get_patches(image, centers, size, mode='axial')) for image, centers in\n",
    "                           zip(labels, n_vox_coord_pos)]\n",
    "    cor_x_neg_patches = [np.array(get_patches(image, centers, size, mode='coronal')) for image, centers in\n",
    "                         zip(images_norm, n_vox_coord_pos)]\n",
    "    cor_y_neg_patches = [np.array(get_patches(image, centers, size, mode='coronal')) for image, centers in\n",
    "                         zip(labels, n_vox_coord_pos)]\n",
    "    sag_x_neg_patches = [np.array(get_patches(image, centers, size, mode='saggital')) for image, centers in\n",
    "                         zip(images_norm, n_vox_coord_pos)]\n",
    "    sag_y_neg_patches = [np.array(get_patches(image, centers, size, mode='saggital')) for image, centers in\n",
    "                         zip(labels, n_vox_coord_pos)]\n",
    "\n",
    "    x_axial = [np.concatenate([p1, p2]) for p1, p2 in zip(axial_x_pos_patches, axial_x_neg_patches)]\n",
    "    y_axial = [np.concatenate([p1, p2]) for p1, p2 in zip(axial_y_pos_patches, axial_y_neg_patches)]\n",
    "    x_cor = [np.concatenate([p1, p2]) for p1, p2 in zip(cor_x_pos_patches, cor_x_neg_patches)]\n",
    "    y_cor = [np.concatenate([p1, p2]) for p1, p2 in zip(cor_y_pos_patches, cor_y_neg_patches)]\n",
    "    x_sag = [np.concatenate([p1, p2]) for p1, p2 in zip(sag_x_pos_patches, sag_x_neg_patches)]\n",
    "    y_sag = [np.concatenate([p1, p2]) for p1, p2 in zip(sag_y_pos_patches, sag_y_neg_patches)]\n",
    "    vox_positions = [np.concatenate([p1, p2]) for p1, p2 in zip(p_vox_coord_pos, n_vox_coord_pos)]\n",
    "\n",
    "    return x_axial, y_axial, x_cor, y_cor, x_sag, y_sag, vox_positions, image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c631567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patches(image, centers, patch_size=(32, 32), mode = 'axial'):\n",
    "    \"\"\"\n",
    "    Returns 2D patches of each of the image views (coronal, axial, sagittal), given a list of voxel coordinates (centers).\n",
    "\n",
    "    Input: \n",
    "    - image: input image\n",
    "    - centers: voxel coordinates\n",
    "    - patch_size to generate the patches [p1, p2]\n",
    "    - mode: 'axial', 'coronal' or 'saggital' to generate different view patches. \n",
    "\n",
    "    Output:\n",
    "    - A list of patches for each voxel passed as input in \"centers\" --> [num_voxels, p1, p2]\n",
    "    \"\"\"\n",
    "\n",
    "    # If the size has even numbers, the patch will be centered. If not, it will try to create an square almost centered.\n",
    "    # By doing this we allow pooling when using encoders/unets.\n",
    "    patches = []\n",
    "    list_of_tuples = all([isinstance(center, tuple) for center in centers])\n",
    "    #sizes_match = [len(center) == len(patch_size) for center in centers]\n",
    "    \n",
    "    # select between axial / coronal / saggital  patches\n",
    "    if mode == 'axial':\n",
    "        patch_size = (patch_size[0], patch_size[1], 1)\n",
    "    if mode == 'coronal':\n",
    "        patch_size = (patch_size[0], 1, patch_size[1])\n",
    "    if mode == 'saggital':\n",
    "        patch_size = (1, patch_size[0], patch_size[1])\n",
    "\n",
    "    patch_half = tuple([idx/2 for idx in patch_size])\n",
    "    new_centers = [map(add, center, patch_half) for center in centers]\n",
    "    padding = tuple((idx, size-idx) for idx, size in zip(patch_half, patch_size))\n",
    "    new_image = np.pad(image, padding, mode='constant', constant_values=0)\n",
    "    \n",
    "    slices = [[slice(c_idx-p_idx, c_idx+(s_idx-p_idx)) for (c_idx, p_idx, s_idx) in zip(center, patch_half, patch_size)] for center in new_centers]\n",
    "    patches = [np.squeeze(new_image[idx]) for idx in slices]\n",
    "\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd1e5f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.squeeze?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daadbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_patches(options, dir_name, mask_name, t1_name, size, seeds=None, balance_neg=True):\n",
    "    \"\"\"\n",
    "    Load all patches for a given subject image passed as argument. This function makes no sense when using only\n",
    "    one channel, but it's useful when using more than one, as load_patch_vectors is called for each of the channels and\n",
    "    the outputs are stacked afterwards.\n",
    "\n",
    "    input:\n",
    "    - dir_name = absolute path of the database images\n",
    "    - label_name: label name\n",
    "    - t1_name: T1 image name\n",
    "    - size: patch size [p1, p2]\n",
    "    - seeds: list of images used as a seed\n",
    "\n",
    "    output:\n",
    "    - x_axial: a list containing all selected patches (axial view) [num_samples, p1, p2]\n",
    "    - y_axial a list containing all selected labels (axial view) [num_samples, p1, p2]\n",
    "    - ...\n",
    "    - y_axial a list containing all selected labels (saggital view) [num_samples, p1, p2]\n",
    "    - centers: voxel coordinates for each patch.\n",
    "    \"\"\"\n",
    "    # Setting up the lists for all images\n",
    "\n",
    "    random_state = np.random.randint(1)\n",
    "\n",
    "    print '    --> Loading ' + t1_name + ' images'\n",
    "    x_axial, y_axial, x_cor, y_cor, x_sag, y_sag, centers, t1_names = load_patch_vectors(options,\n",
    "                                                                                         t1_name,\n",
    "                                                                                         mask_name,\n",
    "                                                                                         dir_name,\n",
    "                                                                                         size,\n",
    "                                                                                         random_state)\n",
    "    # load atlas vectors\n",
    "    x_atlas = get_atlas_vectors(options, dir_name, centers, t1_names)\n",
    "\n",
    "    return x_axial, y_axial, x_cor, y_cor, x_sag, y_sag, x_atlas, t1_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f595872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_voxels(mask, size=None):\n",
    "    \"\"\"\n",
    "    Return the voxel coordinates of non-zero voxels given a input image passed as argument.\n",
    "\n",
    "    Input:\n",
    "    - mask: Input image\n",
    "    - size: if selected, return only a random list of length = size\n",
    "\n",
    "    Output:\n",
    "    - indices_list: a list of non-zero voxel positions expressed as a tuple [(x,y,z)]\n",
    "    \"\"\"\n",
    "    \n",
    "    import random\n",
    "    indices = np.stack(np.nonzero(mask), axis=1)\n",
    "    indices_list = [tuple(idx) for idx in indices]\n",
    "\n",
    "    # if a output size is defined, shuffle and resize the list\n",
    "    if size is not None:\n",
    "        random.shuffle(indices_list)\n",
    "        indices_list = indices_list[:size]\n",
    "\n",
    "    return indices_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caccc6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_shape(image):\n",
    "    if isinstance(image, np.ndarray):\n",
    "        if image.shape[-1] == 1:\n",
    "            return np.squeeze(image)\n",
    "    else:\n",
    "        data = image.get_data()\n",
    "        if data.shape[-1] == 1:\n",
    "            data = np.squeeze(data)\n",
    "        fixed = nib.Nifti1Image(data, image.affine)\n",
    "        return fixed\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9ba5f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
